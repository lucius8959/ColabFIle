{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_prac02.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMUWRfkmf0iO7hs8TIXH9qu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucius8959/ColabFile/blob/master/seq2seq_prac02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCNP0YWAhxvi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d0a852d6-ce3f-4228-8ab5-3228aeca4ebb"
      },
      "source": [
        "!git clone https://github.com/mc6666/MyNeuralNetwork.git\n",
        "#!cd \"/content/MyNeuralNetwork\" \n",
        "#!ls \n",
        "%cd \"/content/MyNeuralNetwork\" \n",
        "!ls\n",
        "#!ls -ltr\n",
        "!python lstm_seq2seq.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MyNeuralNetwork'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Total 109 (delta 0), reused 0 (delta 0), pack-reused 109\u001b[K\n",
            "Receiving objects: 100% (109/109), 19.86 MiB | 14.82 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "/content/MyNeuralNetwork\n",
            " 0_1.py     cnn.config\t\t\t\t RNN.py\n",
            " 0.csv\t    cnn.py\t\t\t\t Sentiment1_GRU.py\n",
            " 0.py\t    cnn.weight\t\t\t\t Sentiment1.py\n",
            " 1.csv\t    Draw.exe\t\t\t\t Sentiment1_test.py\n",
            " 2.csv\t    Draw.pdb\t\t\t\t Sentiment1_training.txt\n",
            " 3.csv\t    GRU.py\t\t\t\t SpeechRecognition\n",
            " 4.csv\t    images\t\t\t\t SSD\n",
            " 5.csv\t    LSTM.py\t\t\t\t style_transfer.py\n",
            " 6.csv\t    lstm_seq2seq.py\t\t\t summarizer.py\n",
            " 7.csv\t    model.config\t\t\t TimeSeries\n",
            " 8.csv\t    model.weight\t\t\t vgg16_vs.py\n",
            " 9.csv\t    pretrained_word_embeddings.py\t'vgg19 show feature.py'\n",
            " cmn-eng    pretrained_word_embeddings_test.py\n",
            " cnn_1.py   README.md\n",
            "2020-08-06 07:08:59.069608: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "Number of samples: 10000\n",
            "Number of unique input tokens: 73\n",
            "Number of unique output tokens: 2640\n",
            "Max sequence length for inputs: 31\n",
            "Max sequence length for outputs: 22\n",
            "tcmalloc: large alloc 2323202048 bytes == 0xc24a000 @  0x7f7489ce9001 0x7f7486503765 0x7f7486567bb0 0x7f7486569a4f 0x7f7486600048 0x50a7f5 0x50cfd6 0x507f24 0x50b053 0x634dd2 0x634e87 0x63863f 0x6391e1 0x4b0dc0 0x7f74898e4b97 0x5b26fa\n",
            "tcmalloc: large alloc 2323202048 bytes == 0x969de000 @  0x7f7489ce9001 0x7f7486503765 0x7f7486567bb0 0x7f7486569a4f 0x7f7486600048 0x50a7f5 0x50cfd6 0x507f24 0x50b053 0x634dd2 0x634e87 0x63863f 0x6391e1 0x4b0dc0 0x7f74898e4b97 0x5b26fa\n",
            "2020-08-06 07:09:03.130411: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-08-06 07:09:03.204919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:03.205756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-06 07:09:03.205820: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-06 07:09:03.499734: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-06 07:09:03.668906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-06 07:09:03.696471: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-06 07:09:03.984565: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-06 07:09:04.016208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-06 07:09:04.572672: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-06 07:09:04.572888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:04.573642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:04.574202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-06 07:09:04.574555: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-08-06 07:09:04.590767: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000134999 Hz\n",
            "2020-08-06 07:09:04.591038: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29f6a00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-06 07:09:04.591071: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-06 07:09:04.770340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:04.771152: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x29f6f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-06 07:09:04.771184: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-08-06 07:09:04.772501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:04.773077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-08-06 07:09:04.773130: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-06 07:09:04.773177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-06 07:09:04.773207: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-08-06 07:09:04.773224: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-08-06 07:09:04.773241: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-08-06 07:09:04.773258: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-08-06 07:09:04.773276: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-08-06 07:09:04.773344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:04.773954: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:04.774505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-08-06 07:09:04.778406: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-08-06 07:09:07.909027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-08-06 07:09:07.909086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-08-06 07:09:07.909100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-08-06 07:09:07.913832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:07.914512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-08-06 07:09:07.915175: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-08-06 07:09:07.915229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "Epoch 1/100\n",
            "2020-08-06 07:09:10.873445: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-08-06 07:09:12.356968: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "125/125 [==============================] - 5s 40ms/step - loss: 2.0531 - val_loss: 2.5388\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.9189 - val_loss: 2.4657\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.8201 - val_loss: 2.3862\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.7375 - val_loss: 2.3160\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.6701 - val_loss: 2.1880\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.5835 - val_loss: 2.1228\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.5119 - val_loss: 2.0760\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.4498 - val_loss: 2.0265\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.3969 - val_loss: 1.9878\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.3511 - val_loss: 1.9419\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 1.3071 - val_loss: 1.9237\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.2662 - val_loss: 1.9017\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.2267 - val_loss: 1.8852\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.1905 - val_loss: 1.8597\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.1554 - val_loss: 1.8475\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.1229 - val_loss: 1.8396\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.0924 - val_loss: 1.8322\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.0631 - val_loss: 1.8248\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 1.0360 - val_loss: 1.8176\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 1.0087 - val_loss: 1.8176\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.9829 - val_loss: 1.8099\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.9582 - val_loss: 1.8052\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.9341 - val_loss: 1.7993\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.9108 - val_loss: 1.8076\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.8879 - val_loss: 1.8085\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.8660 - val_loss: 1.8050\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.8443 - val_loss: 1.8072\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.8240 - val_loss: 1.8003\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.8035 - val_loss: 1.8091\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.7836 - val_loss: 1.8134\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.7640 - val_loss: 1.8123\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.7473 - val_loss: 1.8204\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.7281 - val_loss: 1.8278\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.7109 - val_loss: 1.8321\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.6935 - val_loss: 1.8370\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.6776 - val_loss: 1.8414\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.6607 - val_loss: 1.8421\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.6462 - val_loss: 1.8506\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.6310 - val_loss: 1.8574\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.6163 - val_loss: 1.8576\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.6021 - val_loss: 1.8673\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.5878 - val_loss: 1.8722\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.5747 - val_loss: 1.8825\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.5614 - val_loss: 1.8931\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.5489 - val_loss: 1.8951\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.5372 - val_loss: 1.8993\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.5248 - val_loss: 1.9101\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.5138 - val_loss: 1.9067\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.5027 - val_loss: 1.9222\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.4916 - val_loss: 1.9231\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4809 - val_loss: 1.9298\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4712 - val_loss: 1.9452\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4612 - val_loss: 1.9445\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4515 - val_loss: 1.9504\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4425 - val_loss: 1.9624\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4330 - val_loss: 1.9680\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4253 - val_loss: 1.9736\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4166 - val_loss: 1.9678\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4081 - val_loss: 1.9839\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.4005 - val_loss: 1.9999\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3928 - val_loss: 2.0013\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3851 - val_loss: 2.0080\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3774 - val_loss: 2.0039\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3699 - val_loss: 2.0194\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3627 - val_loss: 2.0344\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3555 - val_loss: 2.0365\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3492 - val_loss: 2.0408\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3430 - val_loss: 2.0334\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3354 - val_loss: 2.0416\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3291 - val_loss: 2.0507\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.3231 - val_loss: 2.0536\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3166 - val_loss: 2.0592\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3105 - val_loss: 2.0696\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.3059 - val_loss: 2.0792\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2984 - val_loss: 2.0834\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2938 - val_loss: 2.0917\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2878 - val_loss: 2.0913\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2824 - val_loss: 2.1058\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2777 - val_loss: 2.1066\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2714 - val_loss: 2.1175\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2667 - val_loss: 2.1166\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2613 - val_loss: 2.1181\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2564 - val_loss: 2.1307\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2517 - val_loss: 2.1291\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2461 - val_loss: 2.1364\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.2415 - val_loss: 2.1505\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2367 - val_loss: 2.1534\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2312 - val_loss: 2.1614\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2273 - val_loss: 2.1794\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 4s 35ms/step - loss: 0.2220 - val_loss: 2.1716\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.2172 - val_loss: 2.1901\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2129 - val_loss: 2.1852\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2083 - val_loss: 2.1888\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.2040 - val_loss: 2.2017\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.1992 - val_loss: 2.2067\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.1956 - val_loss: 2.2104\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 5s 36ms/step - loss: 0.1907 - val_loss: 2.2213\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.1868 - val_loss: 2.2223\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.1823 - val_loss: 2.2296\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 4s 36ms/step - loss: 0.1775 - val_loss: 2.2389\n",
            "*\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: 嗨。\n",
            "\n",
            "*\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: 嗨。\n",
            "\n",
            "*\n",
            "Input sentence: Run.\n",
            "Decoded sentence: 你用跑。\n",
            "\n",
            "*\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: 等等！\n",
            "\n",
            "*\n",
            "Input sentence: Hello!\n",
            "Decoded sentence: 你好。\n",
            "\n",
            "*\n",
            "Input sentence: I try.\n",
            "Decoded sentence: 我開始。\n",
            "\n",
            "*\n",
            "Input sentence: I won!\n",
            "Decoded sentence: 我赢了。\n",
            "\n",
            "*\n",
            "Input sentence: Oh no!\n",
            "Decoded sentence: 不会吧。\n",
            "\n",
            "*\n",
            "Input sentence: Cheers!\n",
            "Decoded sentence: 聖誕節快到會長。\n",
            "\n",
            "*\n",
            "Input sentence: He ran.\n",
            "Decoded sentence: 他跑了。\n",
            "\n",
            "*\n",
            "Input sentence: Hop in.\n",
            "Decoded sentence: 等一下！\n",
            "\n",
            "*\n",
            "Input sentence: I lost.\n",
            "Decoded sentence: 我打算去。\n",
            "\n",
            "*\n",
            "Input sentence: I quit.\n",
            "Decoded sentence: 我同意。\n",
            "\n",
            "*\n",
            "Input sentence: I'm OK.\n",
            "Decoded sentence: 我是个男人。\n",
            "\n",
            "*\n",
            "Input sentence: Listen.\n",
            "Decoded sentence: 听着。\n",
            "\n",
            "*\n",
            "Input sentence: No way!\n",
            "Decoded sentence: 沒人看到。\n",
            "\n",
            "*\n",
            "Input sentence: No way!\n",
            "Decoded sentence: 沒人看到。\n",
            "\n",
            "*\n",
            "Input sentence: Really?\n",
            "Decoded sentence: 你确定？\n",
            "\n",
            "*\n",
            "Input sentence: Try it.\n",
            "Decoded sentence: 试试吧。\n",
            "\n",
            "*\n",
            "Input sentence: We try.\n",
            "Decoded sentence: 我们来试试。\n",
            "\n",
            "*\n",
            "Input sentence: Why me?\n",
            "Decoded sentence: 为什么是我？\n",
            "\n",
            "*\n",
            "Input sentence: Ask Tom.\n",
            "Decoded sentence: 去问汤姆。\n",
            "\n",
            "*\n",
            "Input sentence: Be calm.\n",
            "Decoded sentence: 和气点。\n",
            "\n",
            "*\n",
            "Input sentence: Be fair.\n",
            "Decoded sentence: 来感受一下这个。\n",
            "\n",
            "*\n",
            "Input sentence: Be kind.\n",
            "Decoded sentence: 友善点。\n",
            "\n",
            "*\n",
            "Input sentence: Be nice.\n",
            "Decoded sentence: 和气点。\n",
            "\n",
            "*\n",
            "Input sentence: Call me.\n",
            "Decoded sentence: 叫電話到。\n",
            "\n",
            "*\n",
            "Input sentence: Call us.\n",
            "Decoded sentence: 叫警察！\n",
            "\n",
            "*\n",
            "Input sentence: Come in.\n",
            "Decoded sentence: 进来。\n",
            "\n",
            "*\n",
            "Input sentence: Get Tom.\n",
            "Decoded sentence: 抓住汤姆。\n",
            "\n",
            "*\n",
            "Input sentence: Get out!\n",
            "Decoded sentence: 滾！\n",
            "\n",
            "*\n",
            "Input sentence: Go away!\n",
            "Decoded sentence: 走開！\n",
            "\n",
            "*\n",
            "Input sentence: Go away!\n",
            "Decoded sentence: 走開！\n",
            "\n",
            "*\n",
            "Input sentence: Go away.\n",
            "Decoded sentence: 走開！\n",
            "\n",
            "*\n",
            "Input sentence: Goodbye!\n",
            "Decoded sentence: 再见！\n",
            "\n",
            "*\n",
            "Input sentence: Goodbye!\n",
            "Decoded sentence: 再见！\n",
            "\n",
            "*\n",
            "Input sentence: Hang on!\n",
            "Decoded sentence: 等一下！\n",
            "\n",
            "*\n",
            "Input sentence: He came.\n",
            "Decoded sentence: 他来了。\n",
            "\n",
            "*\n",
            "Input sentence: He runs.\n",
            "Decoded sentence: 他跑。\n",
            "\n",
            "*\n",
            "Input sentence: Help me.\n",
            "Decoded sentence: 帮我一下。\n",
            "\n",
            "*\n",
            "Input sentence: Hold on.\n",
            "Decoded sentence: 停火。\n",
            "\n",
            "*\n",
            "Input sentence: Hug Tom.\n",
            "Decoded sentence: 抱抱汤姆！\n",
            "\n",
            "*\n",
            "Input sentence: I agree.\n",
            "Decoded sentence: 我同意。\n",
            "\n",
            "*\n",
            "Input sentence: I'm ill.\n",
            "Decoded sentence: 我生病了。\n",
            "\n",
            "*\n",
            "Input sentence: I'm old.\n",
            "Decoded sentence: 我还饿了。\n",
            "\n",
            "*\n",
            "Input sentence: It's OK.\n",
            "Decoded sentence: 没关系。\n",
            "\n",
            "*\n",
            "Input sentence: It's me.\n",
            "Decoded sentence: 它是我的。\n",
            "\n",
            "*\n",
            "Input sentence: Join us.\n",
            "Decoded sentence: 来加入我们吧。\n",
            "\n",
            "*\n",
            "Input sentence: Keep it.\n",
            "Decoded sentence: 保持安静\n",
            "\n",
            "*\n",
            "Input sentence: Kiss me.\n",
            "Decoded sentence: 让他。\n",
            "\n",
            "*\n",
            "Input sentence: Perfect!\n",
            "Decoded sentence: 完美！\n",
            "\n",
            "*\n",
            "Input sentence: See you.\n",
            "Decoded sentence: 再见！\n",
            "\n",
            "*\n",
            "Input sentence: Shut up!\n",
            "Decoded sentence: Tom說不是嗎？\n",
            "\n",
            "*\n",
            "Input sentence: Skip it.\n",
            "Decoded sentence: 不管它。\n",
            "\n",
            "*\n",
            "Input sentence: Take it.\n",
            "Decoded sentence: 照顾好自己。\n",
            "\n",
            "*\n",
            "Input sentence: Wake up!\n",
            "Decoded sentence: 醒醒！\n",
            "\n",
            "*\n",
            "Input sentence: Wash up.\n",
            "Decoded sentence: 去清洗一下。\n",
            "\n",
            "*\n",
            "Input sentence: We know.\n",
            "Decoded sentence: 我們知道他們。\n",
            "\n",
            "*\n",
            "Input sentence: Welcome.\n",
            "Decoded sentence: 欢迎。\n",
            "\n",
            "*\n",
            "Input sentence: Who won?\n",
            "Decoded sentence: 谁赢了？\n",
            "\n",
            "*\n",
            "Input sentence: Why not?\n",
            "Decoded sentence: 为什么不？\n",
            "\n",
            "*\n",
            "Input sentence: You run.\n",
            "Decoded sentence: 你的狗非常胖。\n",
            "\n",
            "*\n",
            "Input sentence: Back off.\n",
            "Decoded sentence: 往后退点。\n",
            "\n",
            "*\n",
            "Input sentence: Be still.\n",
            "Decoded sentence: 来感受一下这个。\n",
            "\n",
            "*\n",
            "Input sentence: Cuff him.\n",
            "Decoded sentence: 把他铐上。\n",
            "\n",
            "*\n",
            "Input sentence: Drive on.\n",
            "Decoded sentence: 往前开。\n",
            "\n",
            "*\n",
            "Input sentence: Get away!\n",
            "Decoded sentence: 走開！\n",
            "\n",
            "*\n",
            "Input sentence: Get away!\n",
            "Decoded sentence: 走開！\n",
            "\n",
            "*\n",
            "Input sentence: Get down!\n",
            "Decoded sentence: 走開！\n",
            "\n",
            "*\n",
            "Input sentence: Get lost!\n",
            "Decoded sentence: 滾！\n",
            "\n",
            "*\n",
            "Input sentence: Get real.\n",
            "Decoded sentence: 抓住他。\n",
            "\n",
            "*\n",
            "Input sentence: Grab Tom.\n",
            "Decoded sentence: 抓住汤姆。\n",
            "\n",
            "*\n",
            "Input sentence: Grab him.\n",
            "Decoded sentence: 抓住他。\n",
            "\n",
            "*\n",
            "Input sentence: Have fun.\n",
            "Decoded sentence: 玩得開心。\n",
            "\n",
            "*\n",
            "Input sentence: He tries.\n",
            "Decoded sentence: 他来试试。\n",
            "\n",
            "*\n",
            "Input sentence: Humor me.\n",
            "Decoded sentence: 你就随了我的意吧。\n",
            "\n",
            "*\n",
            "Input sentence: Hurry up.\n",
            "Decoded sentence: 快点！\n",
            "\n",
            "*\n",
            "Input sentence: Hurry up.\n",
            "Decoded sentence: 快点！\n",
            "\n",
            "*\n",
            "Input sentence: I forgot.\n",
            "Decoded sentence: 我忘了。\n",
            "\n",
            "*\n",
            "Input sentence: I resign.\n",
            "Decoded sentence: 我想是這樣。\n",
            "\n",
            "*\n",
            "Input sentence: I'll pay.\n",
            "Decoded sentence: 我會做的。\n",
            "\n",
            "*\n",
            "Input sentence: I'm busy.\n",
            "Decoded sentence: 我很忙。\n",
            "\n",
            "*\n",
            "Input sentence: I'm cold.\n",
            "Decoded sentence: 我很好。\n",
            "\n",
            "*\n",
            "Input sentence: I'm fine.\n",
            "Decoded sentence: 我是从中国来的。\n",
            "\n",
            "*\n",
            "Input sentence: I'm full.\n",
            "Decoded sentence: 我冷。\n",
            "\n",
            "*\n",
            "Input sentence: I'm sick.\n",
            "Decoded sentence: 我生病了。\n",
            "\n",
            "*\n",
            "Input sentence: I'm sick.\n",
            "Decoded sentence: 我生病了。\n",
            "\n",
            "*\n",
            "Input sentence: Leave me.\n",
            "Decoded sentence: 让我一个人呆会儿。\n",
            "\n",
            "*\n",
            "Input sentence: Let's go!\n",
            "Decoded sentence: 我們開始吧！\n",
            "\n",
            "*\n",
            "Input sentence: Let's go!\n",
            "Decoded sentence: 我們開始吧！\n",
            "\n",
            "*\n",
            "Input sentence: Let's go!\n",
            "Decoded sentence: 我們開始吧！\n",
            "\n",
            "*\n",
            "Input sentence: Look out!\n",
            "Decoded sentence: 回头看！\n",
            "\n",
            "*\n",
            "Input sentence: She runs.\n",
            "Decoded sentence: 她跑。\n",
            "\n",
            "*\n",
            "Input sentence: Stand up.\n",
            "Decoded sentence: 起立。\n",
            "\n",
            "*\n",
            "Input sentence: They won.\n",
            "Decoded sentence: 他们都做了。\n",
            "\n",
            "*\n",
            "Input sentence: Tom died.\n",
            "Decoded sentence: 汤姆不干了。\n",
            "\n",
            "*\n",
            "Input sentence: Tom quit.\n",
            "Decoded sentence: 汤姆不干了。\n",
            "\n",
            "*\n",
            "Input sentence: Tom swam.\n",
            "Decoded sentence: 汤姆变胖了。\n",
            "\n",
            "*\n",
            "Input sentence: Trust me.\n",
            "Decoded sentence: 让我进来。\n",
            "\n",
            "*\n",
            "Input sentence: Try hard.\n",
            "Decoded sentence: 试试吧。\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}